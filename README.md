# â˜• Coffee Shop Sales - Time Series Forecasting

> **End-to-end time series forecasting system to predict daily coffee shop revenue 7 days ahead**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“Š Project Overview

This project implements a comprehensive time series forecasting system for coffee shop revenue prediction using real-world sales data from 3 store locations over 6 months.

### Business Objectives
- **Predict daily revenue** 7 days ahead with high accuracy
- **Inventory optimization**: Reduce waste by 10-15%
- **Staff planning**: Right-size labor costs
- **Financial planning**: Better cash flow projection

### Success Metrics
| Metric | Target | Achieved |
|--------|--------|----------|
| MAPE | < 15% | âœ“ **6.68%** (Baseline MA_3) |
| RMSE | < $500 | âœ“ **$468** (Baseline MA_3) |
| RÂ² | > 0.85 | Pending (ensemble models) |

---

## ğŸ“ˆ Dataset Summary

- **Time period**: January 1 - June 30, 2023 (181 days)
- **Transactions**: 149,116 total
- **Revenue**: $698,812 total
- **Growth**: +124.4% from first week to last week
- **Stores**: 3 locations (Lower Manhattan, Hell's Kitchen, Astoria)
- **Categories**: 9 product categories (Coffee 38.6%, Tea 28.1%, Bakery 11.8%)

### Key Insights from EDA
- ğŸ“Š **Strong upward trend**: +103.8% growth Janâ†’Jun
- ğŸ“… **Weekly seasonality**: Clear day-of-week patterns
- â° **Peak hours**: 9-11 AM (highest revenue)
- ğŸª **Balanced stores**: Each ~33% revenue share
- âœ… **High data quality**: 0 missing values, continuous series

---

## ğŸ—ï¸ Project Structure

```
Coffee-shop/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original dataset
â”‚   â””â”€â”€ processed/              # Processed data & features
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                   # Data loading & EDA modules
â”‚   â”œâ”€â”€ features/               # Feature engineering
â”‚   â”œâ”€â”€ models/                 # Model implementations
â”‚   â””â”€â”€ api/                    # REST API (future)
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ models/                     # Saved trained models
â”œâ”€â”€ results/                    # Visualizations & reports
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run_eda.py                 # EDA pipeline
â”œâ”€â”€ run_feature_engineering.py # Feature creation
â”œâ”€â”€ run_baseline_models.py     # Baseline model training
â””â”€â”€ run_ml_models.py           # ML model training
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd Coffee-shop

# Install dependencies
pip install -r requirements.txt
```

### Run Full Pipeline

```bash
# 1. Exploratory Data Analysis
python run_eda.py

# 2. Feature Engineering (creates 73 features)
python run_feature_engineering.py

# 3. Train Baseline Models
python run_baseline_models.py

# 4. Train ML Models
python run_ml_models.py
```

---

## ğŸ”¬ Methodology

### 1. **Exploratory Data Analysis**
- Time series decomposition (trend + seasonality + residual)
- Stationarity tests (ADF, KPSS) â†’ **Non-stationary** series
- ACF/PACF analysis for ARIMA parameter selection
- Temporal pattern discovery (hourly, daily, weekly)
- Store & product category analysis

**Outputs**: 9 visualizations, statistical test results, summary report

### 2. **Feature Engineering**
Created **73 features** across 6 categories:

| Category | Count | Examples |
|----------|-------|----------|
| **Temporal** | 22 | Day of week (cyclical), month, quarter, is_weekend |
| **Lag** | 7 | revenue_lag_1, lag_7, lag_14, lag_28 |
| **Rolling** | 24 | Rolling mean/std/min/max (windows: 3, 7, 14, 28) |
| **Expanding** | 4 | Cumulative mean, std, min, max |
| **Domain** | 13 | Momentum, RSI, distance from MA, volatility |
| **Interaction** | 3 | lag_7 Ã— weekend, rolling_mean Ã— day_of_week |

**Critical**: All features properly shifted to **avoid data leakage**

### 3. **Train/Test Split**
- **Temporal split** (NO shuffling!)
- Train: 80% (122 samples: Jan 29 - May 30)
- Val: 10% (15 samples: May 31 - Jun 14)
- Test: 10% (16 samples: Jun 15 - Jun 30)

### 4. **Baseline Models**

| Model | MAPE | RMSE | RÂ² | Description |
|-------|------|------|-----|-------------|
| **MA_3** ğŸ† | **6.68%** | **$468** | -0.03 | 3-day moving average |
| SARIMA | 7.24% | $538 | -0.36 | ARIMA(1,1,1)Ã—(1,1,1,7) |
| Naive | 8.49% | $549 | -0.41 | Persistence model |
| ARIMA | 8.66% | $557 | -0.46 | ARIMA(1,1,1) |
| MA_7 | 9.24% | $588 | -0.62 | 7-day moving average |

**Winner**: Moving Average 3-day beats target (< 15% MAPE, < $500 RMSE)

### 5. **Machine Learning Models**

| Model | MAPE | RMSE | RÂ² | Top Feature |
|-------|------|------|-----|-------------|
| **LightGBM** ğŸ† | **9.09%** | **$563** | -0.39 | revenue_change_1d |
| XGBoost | 13.33% | $813 | -1.89 | revenue_rolling_range_28 |
| Random Forest | 12.51% | $856 | -2.20 | revenue_lag_1 |

**Key Finding**: Baseline MA_3 outperforms ML models on small test set, likely due to:
- Overfitting (ML train RÂ² = 0.99+)
- Small test size (16 samples)
- Need for hyperparameter tuning

---

## ğŸ“Š Results & Visualizations

### Generated Artifacts

**EDA Outputs** (`results/`):
- `01_timeseries_plot.png` - Revenue over time with moving averages
- `02_decomposition.png` - Trend + Seasonal + Residual components
- `03_acf_pacf.png` - Autocorrelation analysis
- `04_pattern_hourly_pattern.png` - Revenue by hour
- `04_pattern_dayofweek_pattern.png` - Revenue by day of week
- `05_store_analysis.png` - Store performance comparison
- `06_product_analysis.png` - Product category breakdown

**Model Outputs** (`results/`):
- `baseline_forecasts.png` - Baseline model predictions
- `ml_forecasts.png` - ML model predictions
- `baseline_metrics_comparison.png` - Baseline metrics
- `ml_metrics_comparison.png` - ML metrics
- `ml_feature_importance.png` - Top features per model

**Reports** (`results/`):
- `eda_summary.txt` - EDA key findings
- `baseline_summary.txt` - Baseline model results
- `ml_summary.txt` - ML model results with feature importance

---

## ğŸ¯ Model Performance Summary

### Best Overall Model: **Moving Average 3-day**
- **MAPE**: 6.68% (âœ“ Beats 15% target)
- **RMSE**: $468.09 (âœ“ Beats $500 target)
- **Pros**: Simple, interpretable, robust
- **Cons**: Cannot capture complex patterns

### Best ML Model: **LightGBM**
- **MAPE**: 9.09% (âœ“ Beats 15% target)
- **RMSE**: $563.10 (Close to target)
- **Top Features**:
  1. revenue_change_1d (daily change)
  2. revenue_pct_change_1d (% change)
  3. revenue_lag_7 (last week)
  4. revenue_change_7d (week-over-week change)
  5. rolling_mean_7_x_dayofweek (interaction)

---

## ğŸ”® Next Steps (Roadmap)

### Immediate (Week 2-3)
- [ ] **Prophet model** - Facebook's forecasting tool
- [ ] **Ensemble methods** - Combine multiple models
- [ ] **Multi-step forecasting** - Predict full 7-day horizon
- [ ] **Hyperparameter tuning** - Grid search for ML models
- [ ] **Cross-validation** - TimeSeriesSplit validation

### Short-term (Week 3-4)
- [ ] **REST API** - FastAPI endpoints for predictions
- [ ] **Retraining pipeline** - Automated weekly retraining
- [ ] **Monitoring** - Performance tracking & alerts
- [ ] **Docker containerization** - Easy deployment
- [ ] **Model Card** - Detailed model documentation

### Long-term Improvements
- [ ] Add external features (weather, holidays, events)
- [ ] Hourly forecasting (more granular)
- [ ] Product-level forecasting
- [ ] Customer segmentation & behavior analysis
- [ ] Deep learning models (LSTM, Transformer)
- [ ] Anomaly detection for unusual patterns

---

## ğŸ“š Technical Stack

### Core Libraries
- **Data**: `pandas`, `numpy`
- **Visualization**: `matplotlib`, `seaborn`, `plotly`
- **Statistics**: `statsmodels` (ARIMA, diagnostics)
- **ML**: `scikit-learn`, `xgboost`, `lightgbm`
- **Time Series**: `prophet` (planned)

### Tools & Infrastructure
- **Version Control**: Git
- **Environment**: Python 3.10+
- **Notebooks**: Jupyter
- **API**: FastAPI (planned)
- **Containerization**: Docker (planned)

---

## ğŸ“ Key Learnings

### What Worked Well
âœ… **Clean data** - 0 missing values saved significant preprocessing time
âœ… **Strong signal** - Clear trend (+124% growth) makes forecasting easier
âœ… **Feature engineering** - 73 well-designed features capture patterns
âœ… **Simple baselines** - MA_3 proves simple models can be very effective

### Challenges
âš ï¸ **Short history** - Only 6 months limits yearly seasonality detection
âš ï¸ **Small test set** - 16 samples makes evaluation less robust
âš ï¸ **Overfitting** - ML models overfit training data (RÂ² = 0.99+)
âš ï¸ **Non-stationarity** - Requires differencing or detrending

### Best Practices Applied
âœ“ **Temporal split** - Never shuffle time series data
âœ“ **Data leakage prevention** - All features properly shifted
âœ“ **Multiple models** - Compare 8+ different approaches
âœ“ **Proper metrics** - MAPE, RMSE, RÂ², MBD for comprehensive evaluation
âœ“ **Visualizations** - Clear plots for communication

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ‘¥ Contact

For questions or collaboration:
- **Project**: Coffee Shop Revenue Forecasting
- **Created**: November 2025
- **Status**: In Development (Week 2 of 4)

---

## ğŸ™ Acknowledgments

- Dataset: Coffee Shop Sales (Kaggle/synthetic data)
- References:
  - "Forecasting: Principles and Practice" - Rob Hyndman
  - Facebook Prophet documentation
  - XGBoost & LightGBM official docs

---

**Last Updated**: November 15, 2025
**Version**: 0.2.0
**Progress**: Week 2 - Advanced Models Complete
